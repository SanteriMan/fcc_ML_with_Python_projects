{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of fcc_predict_health_costs_with_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanteriMan/freecodecamp_ML_projects/blob/master/Copy_of_fcc_predict_health_costs_with_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9TX15KOkPBV",
        "colab_type": "text"
      },
      "source": [
        "*Note: You are currently reading this using Google Colaboratory which is a cloud-hosted version of Jupyter Notebook. This is a document containing both text cells for documentation and runnable code cells. If you are unfamiliar with Jupyter Notebook, watch this 3-minute introduction before starting this challenge: https://www.youtube.com/watch?v=inN8seMm7UI*\n",
        "\n",
        "---\n",
        "\n",
        "In this challenge, you will predict healthcare costs using a regression algorithm.\n",
        "\n",
        "You are given a dataset that contains information about different people including their healthcare costs. Use the data to predict healthcare costs based on new data.\n",
        "\n",
        "The first two cells of this notebook import libraries and the data.\n",
        "\n",
        "Make sure to convert categorical data to numbers. Use 80% of the data as the `train_dataset` and 20% of the data as the `test_dataset`.\n",
        "\n",
        "`pop` off the \"expenses\" column from these datasets to create new datasets called `train_labels` and `test_labels`. Use these labels when training your model.\n",
        "\n",
        "Create a model and train it with the `train_dataset`. Run the final cell in this notebook to check your model. The final cell will use the unseen `test_dataset` to check how well the model generalizes.\n",
        "\n",
        "To pass the challenge, `model.evaluate` must return a Mean Absolute Error of under 3500. This means it predicts health care costs correctly within $3500.\n",
        "\n",
        "The final cell will also predict expenses using the `test_dataset` and graph the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1rRo8oNqZ-Rj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d4aba78-4e0e-451e-9306-1092041a45ba"
      },
      "source": [
        "# Import libraries. You may or may not use all of these.\n",
        "!pip install -q git+https://github.com/tensorflow/docs\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CiX2FI4gZtTt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "a4d0140e-2f28-438a-8dc2-2ce1005bbb57"
      },
      "source": [
        "# Import data\n",
        "dataset_path = keras.utils.get_file(\"insurance.csv\", \"https://cdn.freecodecamp.org/project-data/health-costs/insurance.csv\")\n",
        "dataset = pd.read_csv(dataset_path)\n",
        "dataset.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://cdn.freecodecamp.org/project-data/health-costs/insurance.csv\n",
            "57344/50264 [==================================] - 0s 1us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>expenses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.9</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.8</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.0</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.7</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.9</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.86</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     sex   bmi  children smoker     region  expenses\n",
              "0   19  female  27.9         0    yes  southwest  16884.92\n",
              "1   18    male  33.8         1     no  southeast   1725.55\n",
              "2   28    male  33.0         3     no  southeast   4449.46\n",
              "3   33    male  22.7         0     no  northwest  21984.47\n",
              "4   32    male  28.9         0     no  northwest   3866.86"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LcopvQh3X-kX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d9fe84eb-3336-44ab-d675-781aa04f9e4f"
      },
      "source": [
        "dataset['sex'] = pd.Categorical(dataset['sex'])\n",
        "dataset['sex'] = dataset['sex'].cat.codes\n",
        "dataset['smoker'] = pd.Categorical(dataset['smoker'])\n",
        "dataset['smoker'] = dataset['smoker'].cat.codes\n",
        "dataset['region'] = pd.Categorical(dataset['region'])\n",
        "dataset['region'] = dataset['region'].cat.codes\n",
        "dataset.head()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>expenses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>27.9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>16884.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>33.8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1725.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>33.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4449.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>22.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>21984.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>28.9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3866.86</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  sex   bmi  children  smoker  region  expenses\n",
              "0   19    0  27.9         0       1       3  16884.92\n",
              "1   18    1  33.8         1       0       2   1725.55\n",
              "2   28    1  33.0         3       0       2   4449.46\n",
              "3   33    1  22.7         0       0       1  21984.47\n",
              "4   32    1  28.9         0       0       1   3866.86"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGCY8Zab0Uvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)\n",
        "\n",
        "train_labels = train_dataset.pop(\"expenses\")\n",
        "test_labels = test_dataset.pop(\"expenses\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypAVS2Gb3PYC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "6846b396-bd30-4a61-c97e-a74505e4a766"
      },
      "source": [
        "train_stats = train_dataset.describe()\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>1070.0</td>\n",
              "      <td>39.036449</td>\n",
              "      <td>14.142122</td>\n",
              "      <td>18.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>64.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sex</th>\n",
              "      <td>1070.0</td>\n",
              "      <td>0.498131</td>\n",
              "      <td>0.500230</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bmi</th>\n",
              "      <td>1070.0</td>\n",
              "      <td>30.737290</td>\n",
              "      <td>6.065193</td>\n",
              "      <td>16.0</td>\n",
              "      <td>26.3</td>\n",
              "      <td>30.5</td>\n",
              "      <td>34.8</td>\n",
              "      <td>53.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>children</th>\n",
              "      <td>1070.0</td>\n",
              "      <td>1.093458</td>\n",
              "      <td>1.211364</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smoker</th>\n",
              "      <td>1070.0</td>\n",
              "      <td>0.199065</td>\n",
              "      <td>0.399484</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>region</th>\n",
              "      <td>1070.0</td>\n",
              "      <td>1.501869</td>\n",
              "      <td>1.103399</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           count       mean        std   min   25%   50%   75%   max\n",
              "age       1070.0  39.036449  14.142122  18.0  26.0  39.0  51.0  64.0\n",
              "sex       1070.0   0.498131   0.500230   0.0   0.0   0.0   1.0   1.0\n",
              "bmi       1070.0  30.737290   6.065193  16.0  26.3  30.5  34.8  53.1\n",
              "children  1070.0   1.093458   1.211364   0.0   0.0   1.0   2.0   5.0\n",
              "smoker    1070.0   0.199065   0.399484   0.0   0.0   0.0   0.0   1.0\n",
              "region    1070.0   1.501869   1.103399   0.0   1.0   2.0   2.0   3.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3E1A8_u3GLH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS8Y93wb3kUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "  ])\n",
        "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "model.compile(loss='mse',\n",
        "                optimizer='adam',\n",
        "                metrics=['mae','mse'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TObVmcBn3vTF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cd26c836-37bd-45cc-c9da-b98b82ca8dfb"
      },
      "source": [
        "history = model.fit(normed_train_data, train_labels, epochs= 200,validation_split = 0.2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 21117600.0000 - mae: 2757.2305 - mse: 21117600.0000 - val_loss: 24244736.0000 - val_mae: 3016.3440 - val_mse: 24244736.0000\n",
            "Epoch 2/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 21106278.0000 - mae: 2746.4883 - mse: 21106278.0000 - val_loss: 24207754.0000 - val_mae: 3002.4656 - val_mse: 24207754.0000\n",
            "Epoch 3/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 21081686.0000 - mae: 2742.9597 - mse: 21081686.0000 - val_loss: 24181752.0000 - val_mae: 3014.1880 - val_mse: 24181752.0000\n",
            "Epoch 4/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 21062340.0000 - mae: 2751.5352 - mse: 21062340.0000 - val_loss: 24167768.0000 - val_mae: 3019.3403 - val_mse: 24167768.0000\n",
            "Epoch 5/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 21043264.0000 - mae: 2743.1235 - mse: 21043264.0000 - val_loss: 24143796.0000 - val_mae: 3014.8777 - val_mse: 24143796.0000\n",
            "Epoch 6/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 21032606.0000 - mae: 2754.5730 - mse: 21032606.0000 - val_loss: 24096740.0000 - val_mae: 3012.5566 - val_mse: 24096740.0000\n",
            "Epoch 7/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 21002730.0000 - mae: 2743.7905 - mse: 21002730.0000 - val_loss: 24052424.0000 - val_mae: 2997.3145 - val_mse: 24052424.0000\n",
            "Epoch 8/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20981678.0000 - mae: 2746.0178 - mse: 20981678.0000 - val_loss: 24029070.0000 - val_mae: 3005.9019 - val_mse: 24029070.0000\n",
            "Epoch 9/200\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 20965902.0000 - mae: 2732.5571 - mse: 20965902.0000 - val_loss: 23973230.0000 - val_mae: 2989.5042 - val_mse: 23973230.0000\n",
            "Epoch 10/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20942104.0000 - mae: 2741.0681 - mse: 20942104.0000 - val_loss: 23958308.0000 - val_mae: 2997.4480 - val_mse: 23958308.0000\n",
            "Epoch 11/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20933096.0000 - mae: 2729.9512 - mse: 20933096.0000 - val_loss: 23923704.0000 - val_mae: 2985.6340 - val_mse: 23923704.0000\n",
            "Epoch 12/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20904104.0000 - mae: 2739.9629 - mse: 20904104.0000 - val_loss: 23907750.0000 - val_mae: 3011.5198 - val_mse: 23907750.0000\n",
            "Epoch 13/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20893978.0000 - mae: 2734.7891 - mse: 20893978.0000 - val_loss: 23869502.0000 - val_mae: 2991.9177 - val_mse: 23869502.0000\n",
            "Epoch 14/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20854006.0000 - mae: 2733.6648 - mse: 20854006.0000 - val_loss: 23842878.0000 - val_mae: 2997.4954 - val_mse: 23842878.0000\n",
            "Epoch 15/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 20864056.0000 - mae: 2724.0698 - mse: 20864056.0000 - val_loss: 23818062.0000 - val_mae: 2979.9951 - val_mse: 23818062.0000\n",
            "Epoch 16/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20835852.0000 - mae: 2728.0688 - mse: 20835852.0000 - val_loss: 23781338.0000 - val_mae: 2985.3931 - val_mse: 23781338.0000\n",
            "Epoch 17/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20804632.0000 - mae: 2733.3313 - mse: 20804632.0000 - val_loss: 23764418.0000 - val_mae: 2987.7336 - val_mse: 23764418.0000\n",
            "Epoch 18/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20779956.0000 - mae: 2731.7739 - mse: 20779956.0000 - val_loss: 23732392.0000 - val_mae: 2990.0415 - val_mse: 23732392.0000\n",
            "Epoch 19/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20763680.0000 - mae: 2731.0173 - mse: 20763680.0000 - val_loss: 23681948.0000 - val_mae: 2982.2751 - val_mse: 23681948.0000\n",
            "Epoch 20/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20749230.0000 - mae: 2726.9692 - mse: 20749230.0000 - val_loss: 23675968.0000 - val_mae: 2990.3884 - val_mse: 23675968.0000\n",
            "Epoch 21/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 20730366.0000 - mae: 2727.2822 - mse: 20730366.0000 - val_loss: 23613284.0000 - val_mae: 2964.4275 - val_mse: 23613284.0000\n",
            "Epoch 22/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20700622.0000 - mae: 2715.9624 - mse: 20700622.0000 - val_loss: 23605214.0000 - val_mae: 2970.0422 - val_mse: 23605214.0000\n",
            "Epoch 23/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20691846.0000 - mae: 2715.4414 - mse: 20691846.0000 - val_loss: 23579940.0000 - val_mae: 2971.9434 - val_mse: 23579940.0000\n",
            "Epoch 24/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20665584.0000 - mae: 2708.5571 - mse: 20665584.0000 - val_loss: 23531388.0000 - val_mae: 2951.8037 - val_mse: 23531388.0000\n",
            "Epoch 25/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20641024.0000 - mae: 2711.4607 - mse: 20641024.0000 - val_loss: 23504876.0000 - val_mae: 2966.2197 - val_mse: 23504876.0000\n",
            "Epoch 26/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20631628.0000 - mae: 2697.6223 - mse: 20631628.0000 - val_loss: 23465116.0000 - val_mae: 2936.7202 - val_mse: 23465116.0000\n",
            "Epoch 27/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20625710.0000 - mae: 2696.3806 - mse: 20625710.0000 - val_loss: 23448242.0000 - val_mae: 2948.4734 - val_mse: 23448242.0000\n",
            "Epoch 28/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20581642.0000 - mae: 2709.0486 - mse: 20581642.0000 - val_loss: 23415762.0000 - val_mae: 2968.8777 - val_mse: 23415762.0000\n",
            "Epoch 29/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20581498.0000 - mae: 2715.4224 - mse: 20581498.0000 - val_loss: 23412094.0000 - val_mae: 2963.5120 - val_mse: 23412094.0000\n",
            "Epoch 30/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20543924.0000 - mae: 2705.6394 - mse: 20543924.0000 - val_loss: 23355002.0000 - val_mae: 2947.4407 - val_mse: 23355002.0000\n",
            "Epoch 31/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20525102.0000 - mae: 2699.5701 - mse: 20525102.0000 - val_loss: 23332572.0000 - val_mae: 2953.5085 - val_mse: 23332572.0000\n",
            "Epoch 32/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20518420.0000 - mae: 2707.3894 - mse: 20518420.0000 - val_loss: 23300710.0000 - val_mae: 2945.7578 - val_mse: 23300710.0000\n",
            "Epoch 33/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20486696.0000 - mae: 2686.0198 - mse: 20486696.0000 - val_loss: 23252404.0000 - val_mae: 2928.7073 - val_mse: 23252404.0000\n",
            "Epoch 34/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20461530.0000 - mae: 2687.4775 - mse: 20461530.0000 - val_loss: 23230588.0000 - val_mae: 2942.2908 - val_mse: 23230590.0000\n",
            "Epoch 35/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 20455898.0000 - mae: 2691.7390 - mse: 20455898.0000 - val_loss: 23228942.0000 - val_mae: 2941.5947 - val_mse: 23228942.0000\n",
            "Epoch 36/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20428366.0000 - mae: 2690.6150 - mse: 20428366.0000 - val_loss: 23181302.0000 - val_mae: 2930.4414 - val_mse: 23181302.0000\n",
            "Epoch 37/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20409440.0000 - mae: 2683.4207 - mse: 20409440.0000 - val_loss: 23151418.0000 - val_mae: 2932.9031 - val_mse: 23151418.0000\n",
            "Epoch 38/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20410536.0000 - mae: 2677.5906 - mse: 20410536.0000 - val_loss: 23116110.0000 - val_mae: 2923.5608 - val_mse: 23116110.0000\n",
            "Epoch 39/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20366852.0000 - mae: 2684.5317 - mse: 20366852.0000 - val_loss: 23100852.0000 - val_mae: 2944.1594 - val_mse: 23100852.0000\n",
            "Epoch 40/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20374696.0000 - mae: 2682.0488 - mse: 20374696.0000 - val_loss: 23048716.0000 - val_mae: 2915.0090 - val_mse: 23048716.0000\n",
            "Epoch 41/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 20335948.0000 - mae: 2685.9922 - mse: 20335948.0000 - val_loss: 23034238.0000 - val_mae: 2928.0955 - val_mse: 23034238.0000\n",
            "Epoch 42/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 20320060.0000 - mae: 2686.3049 - mse: 20320060.0000 - val_loss: 22986430.0000 - val_mae: 2925.0535 - val_mse: 22986430.0000\n",
            "Epoch 43/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20312954.0000 - mae: 2661.0479 - mse: 20312954.0000 - val_loss: 22955230.0000 - val_mae: 2901.8870 - val_mse: 22955230.0000\n",
            "Epoch 44/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20277664.0000 - mae: 2673.1775 - mse: 20277664.0000 - val_loss: 22954792.0000 - val_mae: 2922.0325 - val_mse: 22954792.0000\n",
            "Epoch 45/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20259172.0000 - mae: 2664.5381 - mse: 20259172.0000 - val_loss: 22912632.0000 - val_mae: 2908.1208 - val_mse: 22912632.0000\n",
            "Epoch 46/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20243966.0000 - mae: 2673.7441 - mse: 20243966.0000 - val_loss: 22876030.0000 - val_mae: 2909.6765 - val_mse: 22876030.0000\n",
            "Epoch 47/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20219858.0000 - mae: 2671.9363 - mse: 20219858.0000 - val_loss: 22866010.0000 - val_mae: 2915.6218 - val_mse: 22866010.0000\n",
            "Epoch 48/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20199368.0000 - mae: 2667.8755 - mse: 20199368.0000 - val_loss: 22827748.0000 - val_mae: 2905.5862 - val_mse: 22827748.0000\n",
            "Epoch 49/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 20196206.0000 - mae: 2648.7346 - mse: 20196206.0000 - val_loss: 22795292.0000 - val_mae: 2879.9343 - val_mse: 22795292.0000\n",
            "Epoch 50/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20164146.0000 - mae: 2648.1255 - mse: 20164146.0000 - val_loss: 22749132.0000 - val_mae: 2894.9006 - val_mse: 22749132.0000\n",
            "Epoch 51/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20155872.0000 - mae: 2652.2993 - mse: 20155872.0000 - val_loss: 22719502.0000 - val_mae: 2885.8677 - val_mse: 22719502.0000\n",
            "Epoch 52/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 20139902.0000 - mae: 2648.9082 - mse: 20139902.0000 - val_loss: 22685964.0000 - val_mae: 2884.2739 - val_mse: 22685964.0000\n",
            "Epoch 53/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20109948.0000 - mae: 2646.7703 - mse: 20109948.0000 - val_loss: 22659162.0000 - val_mae: 2883.4631 - val_mse: 22659162.0000\n",
            "Epoch 54/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20115516.0000 - mae: 2663.9360 - mse: 20115516.0000 - val_loss: 22636444.0000 - val_mae: 2892.4270 - val_mse: 22636444.0000\n",
            "Epoch 55/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 20090620.0000 - mae: 2636.9597 - mse: 20090620.0000 - val_loss: 22602922.0000 - val_mae: 2870.8533 - val_mse: 22602922.0000\n",
            "Epoch 56/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20051886.0000 - mae: 2637.6833 - mse: 20051886.0000 - val_loss: 22591928.0000 - val_mae: 2871.9951 - val_mse: 22591928.0000\n",
            "Epoch 57/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20042756.0000 - mae: 2644.9614 - mse: 20042756.0000 - val_loss: 22551696.0000 - val_mae: 2878.1787 - val_mse: 22551696.0000\n",
            "Epoch 58/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20022732.0000 - mae: 2643.2439 - mse: 20022732.0000 - val_loss: 22540728.0000 - val_mae: 2883.5764 - val_mse: 22540728.0000\n",
            "Epoch 59/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 20000568.0000 - mae: 2635.8857 - mse: 20000568.0000 - val_loss: 22499998.0000 - val_mae: 2871.1741 - val_mse: 22499998.0000\n",
            "Epoch 60/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19987698.0000 - mae: 2643.3896 - mse: 19987698.0000 - val_loss: 22474230.0000 - val_mae: 2884.3218 - val_mse: 22474230.0000\n",
            "Epoch 61/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19970564.0000 - mae: 2633.5432 - mse: 19970564.0000 - val_loss: 22446402.0000 - val_mae: 2870.3335 - val_mse: 22446402.0000\n",
            "Epoch 62/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19953224.0000 - mae: 2629.2275 - mse: 19953224.0000 - val_loss: 22429160.0000 - val_mae: 2858.4326 - val_mse: 22429160.0000\n",
            "Epoch 63/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 19935132.0000 - mae: 2642.7363 - mse: 19935132.0000 - val_loss: 22393222.0000 - val_mae: 2873.6250 - val_mse: 22393222.0000\n",
            "Epoch 64/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19929980.0000 - mae: 2625.7073 - mse: 19929980.0000 - val_loss: 22340518.0000 - val_mae: 2843.3889 - val_mse: 22340518.0000\n",
            "Epoch 65/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19895306.0000 - mae: 2615.3250 - mse: 19895306.0000 - val_loss: 22327030.0000 - val_mae: 2854.8977 - val_mse: 22327030.0000\n",
            "Epoch 66/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19899066.0000 - mae: 2612.1711 - mse: 19899066.0000 - val_loss: 22298616.0000 - val_mae: 2830.3269 - val_mse: 22298616.0000\n",
            "Epoch 67/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19872456.0000 - mae: 2630.5798 - mse: 19872456.0000 - val_loss: 22262370.0000 - val_mae: 2863.8860 - val_mse: 22262370.0000\n",
            "Epoch 68/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19840110.0000 - mae: 2619.2158 - mse: 19840110.0000 - val_loss: 22237284.0000 - val_mae: 2850.4885 - val_mse: 22237284.0000\n",
            "Epoch 69/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 19817874.0000 - mae: 2613.5002 - mse: 19817874.0000 - val_loss: 22209596.0000 - val_mae: 2843.6995 - val_mse: 22209596.0000\n",
            "Epoch 70/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19808102.0000 - mae: 2621.1892 - mse: 19808102.0000 - val_loss: 22187568.0000 - val_mae: 2858.1890 - val_mse: 22187568.0000\n",
            "Epoch 71/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19797070.0000 - mae: 2620.1506 - mse: 19797070.0000 - val_loss: 22140620.0000 - val_mae: 2837.3760 - val_mse: 22140620.0000\n",
            "Epoch 72/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19765366.0000 - mae: 2608.1262 - mse: 19765366.0000 - val_loss: 22101760.0000 - val_mae: 2829.9912 - val_mse: 22101760.0000\n",
            "Epoch 73/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 19741272.0000 - mae: 2602.6372 - mse: 19741272.0000 - val_loss: 22093278.0000 - val_mae: 2825.4751 - val_mse: 22093278.0000\n",
            "Epoch 74/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19731106.0000 - mae: 2608.1736 - mse: 19731106.0000 - val_loss: 22064544.0000 - val_mae: 2832.9766 - val_mse: 22064544.0000\n",
            "Epoch 75/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 19712246.0000 - mae: 2609.7952 - mse: 19712246.0000 - val_loss: 22040466.0000 - val_mae: 2834.2405 - val_mse: 22040464.0000\n",
            "Epoch 76/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19692476.0000 - mae: 2609.8694 - mse: 19692476.0000 - val_loss: 22013184.0000 - val_mae: 2823.9180 - val_mse: 22013184.0000\n",
            "Epoch 77/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19689050.0000 - mae: 2591.3418 - mse: 19689050.0000 - val_loss: 21969570.0000 - val_mae: 2810.3083 - val_mse: 21969570.0000\n",
            "Epoch 78/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19660402.0000 - mae: 2599.3645 - mse: 19660402.0000 - val_loss: 21947476.0000 - val_mae: 2822.3689 - val_mse: 21947476.0000\n",
            "Epoch 79/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19646770.0000 - mae: 2596.9331 - mse: 19646770.0000 - val_loss: 21947042.0000 - val_mae: 2814.5017 - val_mse: 21947042.0000\n",
            "Epoch 80/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19630650.0000 - mae: 2596.0437 - mse: 19630650.0000 - val_loss: 21914962.0000 - val_mae: 2828.0791 - val_mse: 21914962.0000\n",
            "Epoch 81/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 19616356.0000 - mae: 2587.9299 - mse: 19616356.0000 - val_loss: 21865620.0000 - val_mae: 2800.3557 - val_mse: 21865620.0000\n",
            "Epoch 82/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19600082.0000 - mae: 2599.8650 - mse: 19600082.0000 - val_loss: 21843164.0000 - val_mae: 2815.8464 - val_mse: 21843164.0000\n",
            "Epoch 83/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19573538.0000 - mae: 2586.1006 - mse: 19573538.0000 - val_loss: 21818744.0000 - val_mae: 2800.6074 - val_mse: 21818744.0000\n",
            "Epoch 84/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19563028.0000 - mae: 2570.3687 - mse: 19563028.0000 - val_loss: 21799790.0000 - val_mae: 2794.3464 - val_mse: 21799790.0000\n",
            "Epoch 85/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19538756.0000 - mae: 2581.8694 - mse: 19538756.0000 - val_loss: 21762266.0000 - val_mae: 2800.2803 - val_mse: 21762266.0000\n",
            "Epoch 86/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 19530516.0000 - mae: 2590.9131 - mse: 19530516.0000 - val_loss: 21750048.0000 - val_mae: 2813.7410 - val_mse: 21750048.0000\n",
            "Epoch 87/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19506152.0000 - mae: 2594.1831 - mse: 19506152.0000 - val_loss: 21716342.0000 - val_mae: 2798.0398 - val_mse: 21716342.0000\n",
            "Epoch 88/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19487690.0000 - mae: 2576.0164 - mse: 19487690.0000 - val_loss: 21678174.0000 - val_mae: 2784.1648 - val_mse: 21678174.0000\n",
            "Epoch 89/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19465696.0000 - mae: 2570.7915 - mse: 19465696.0000 - val_loss: 21657176.0000 - val_mae: 2786.1128 - val_mse: 21657176.0000\n",
            "Epoch 90/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19464456.0000 - mae: 2581.8257 - mse: 19464456.0000 - val_loss: 21649958.0000 - val_mae: 2795.6934 - val_mse: 21649958.0000\n",
            "Epoch 91/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19455430.0000 - mae: 2555.4158 - mse: 19455430.0000 - val_loss: 21590842.0000 - val_mae: 2754.1379 - val_mse: 21590842.0000\n",
            "Epoch 92/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19415062.0000 - mae: 2562.3669 - mse: 19415062.0000 - val_loss: 21574660.0000 - val_mae: 2778.8398 - val_mse: 21574660.0000\n",
            "Epoch 93/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19404448.0000 - mae: 2571.8154 - mse: 19404448.0000 - val_loss: 21538766.0000 - val_mae: 2775.4749 - val_mse: 21538766.0000\n",
            "Epoch 94/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19388168.0000 - mae: 2581.1179 - mse: 19388168.0000 - val_loss: 21532048.0000 - val_mae: 2785.4431 - val_mse: 21532048.0000\n",
            "Epoch 95/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19368964.0000 - mae: 2567.7173 - mse: 19368964.0000 - val_loss: 21495748.0000 - val_mae: 2771.2913 - val_mse: 21495748.0000\n",
            "Epoch 96/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19363320.0000 - mae: 2550.2886 - mse: 19363320.0000 - val_loss: 21478952.0000 - val_mae: 2759.8960 - val_mse: 21478952.0000\n",
            "Epoch 97/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19333812.0000 - mae: 2552.2690 - mse: 19333810.0000 - val_loss: 21454518.0000 - val_mae: 2771.7161 - val_mse: 21454518.0000\n",
            "Epoch 98/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19341704.0000 - mae: 2569.9280 - mse: 19341704.0000 - val_loss: 21425798.0000 - val_mae: 2763.9512 - val_mse: 21425798.0000\n",
            "Epoch 99/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19297408.0000 - mae: 2555.5762 - mse: 19297408.0000 - val_loss: 21407110.0000 - val_mae: 2762.4255 - val_mse: 21407110.0000\n",
            "Epoch 100/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19286110.0000 - mae: 2558.3628 - mse: 19286110.0000 - val_loss: 21378136.0000 - val_mae: 2770.9275 - val_mse: 21378136.0000\n",
            "Epoch 101/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 19280578.0000 - mae: 2552.9968 - mse: 19280578.0000 - val_loss: 21331326.0000 - val_mae: 2762.4883 - val_mse: 21331326.0000\n",
            "Epoch 102/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19284758.0000 - mae: 2548.1880 - mse: 19284758.0000 - val_loss: 21327350.0000 - val_mae: 2739.5486 - val_mse: 21327350.0000\n",
            "Epoch 103/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19244074.0000 - mae: 2535.4138 - mse: 19244074.0000 - val_loss: 21281246.0000 - val_mae: 2744.7053 - val_mse: 21281246.0000\n",
            "Epoch 104/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19224572.0000 - mae: 2552.7078 - mse: 19224572.0000 - val_loss: 21273500.0000 - val_mae: 2762.7346 - val_mse: 21273500.0000\n",
            "Epoch 105/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19222678.0000 - mae: 2560.5168 - mse: 19222678.0000 - val_loss: 21237460.0000 - val_mae: 2764.4285 - val_mse: 21237460.0000\n",
            "Epoch 106/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19200038.0000 - mae: 2537.6863 - mse: 19200038.0000 - val_loss: 21204104.0000 - val_mae: 2737.5212 - val_mse: 21204104.0000\n",
            "Epoch 107/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19180430.0000 - mae: 2544.1040 - mse: 19180430.0000 - val_loss: 21209006.0000 - val_mae: 2749.5417 - val_mse: 21209006.0000\n",
            "Epoch 108/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19164694.0000 - mae: 2539.6399 - mse: 19164694.0000 - val_loss: 21150802.0000 - val_mae: 2725.4937 - val_mse: 21150802.0000\n",
            "Epoch 109/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19167942.0000 - mae: 2537.1785 - mse: 19167942.0000 - val_loss: 21162506.0000 - val_mae: 2732.8813 - val_mse: 21162506.0000\n",
            "Epoch 110/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 19135284.0000 - mae: 2528.3115 - mse: 19135284.0000 - val_loss: 21118910.0000 - val_mae: 2721.7288 - val_mse: 21118910.0000\n",
            "Epoch 111/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19120076.0000 - mae: 2536.6265 - mse: 19120076.0000 - val_loss: 21078492.0000 - val_mae: 2742.9001 - val_mse: 21078492.0000\n",
            "Epoch 112/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19110336.0000 - mae: 2525.3540 - mse: 19110336.0000 - val_loss: 21038908.0000 - val_mae: 2717.8066 - val_mse: 21038908.0000\n",
            "Epoch 113/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19090398.0000 - mae: 2529.0405 - mse: 19090398.0000 - val_loss: 21031286.0000 - val_mae: 2727.7617 - val_mse: 21031286.0000\n",
            "Epoch 114/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19077816.0000 - mae: 2526.3203 - mse: 19077816.0000 - val_loss: 21029678.0000 - val_mae: 2716.8142 - val_mse: 21029678.0000\n",
            "Epoch 115/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19059932.0000 - mae: 2517.2327 - mse: 19059932.0000 - val_loss: 20992698.0000 - val_mae: 2702.5579 - val_mse: 20992698.0000\n",
            "Epoch 116/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19049366.0000 - mae: 2505.9419 - mse: 19049366.0000 - val_loss: 20956016.0000 - val_mae: 2697.9958 - val_mse: 20956016.0000\n",
            "Epoch 117/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19042466.0000 - mae: 2528.8408 - mse: 19042466.0000 - val_loss: 20944478.0000 - val_mae: 2718.6995 - val_mse: 20944478.0000\n",
            "Epoch 118/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19021806.0000 - mae: 2508.6265 - mse: 19021806.0000 - val_loss: 20917250.0000 - val_mae: 2702.2832 - val_mse: 20917250.0000\n",
            "Epoch 119/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19005302.0000 - mae: 2512.7769 - mse: 19005302.0000 - val_loss: 20890742.0000 - val_mae: 2702.3506 - val_mse: 20890742.0000\n",
            "Epoch 120/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 19005054.0000 - mae: 2525.9377 - mse: 19005054.0000 - val_loss: 20898058.0000 - val_mae: 2720.3867 - val_mse: 20898058.0000\n",
            "Epoch 121/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18978676.0000 - mae: 2504.7134 - mse: 18978676.0000 - val_loss: 20846014.0000 - val_mae: 2686.0549 - val_mse: 20846014.0000\n",
            "Epoch 122/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 18958074.0000 - mae: 2497.3745 - mse: 18958074.0000 - val_loss: 20835024.0000 - val_mae: 2699.3970 - val_mse: 20835024.0000\n",
            "Epoch 123/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 18949036.0000 - mae: 2508.5713 - mse: 18949036.0000 - val_loss: 20797052.0000 - val_mae: 2694.0222 - val_mse: 20797052.0000\n",
            "Epoch 124/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18939058.0000 - mae: 2502.7974 - mse: 18939058.0000 - val_loss: 20776560.0000 - val_mae: 2684.5408 - val_mse: 20776560.0000\n",
            "Epoch 125/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18922930.0000 - mae: 2509.3591 - mse: 18922930.0000 - val_loss: 20759976.0000 - val_mae: 2686.3472 - val_mse: 20759976.0000\n",
            "Epoch 126/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18906500.0000 - mae: 2492.6326 - mse: 18906500.0000 - val_loss: 20739940.0000 - val_mae: 2668.3228 - val_mse: 20739940.0000\n",
            "Epoch 127/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18890458.0000 - mae: 2501.9556 - mse: 18890458.0000 - val_loss: 20715850.0000 - val_mae: 2696.0864 - val_mse: 20715850.0000\n",
            "Epoch 128/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18884504.0000 - mae: 2497.6772 - mse: 18884504.0000 - val_loss: 20689550.0000 - val_mae: 2667.2917 - val_mse: 20689550.0000\n",
            "Epoch 129/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 18862052.0000 - mae: 2495.3660 - mse: 18862052.0000 - val_loss: 20670084.0000 - val_mae: 2689.2034 - val_mse: 20670084.0000\n",
            "Epoch 130/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18861446.0000 - mae: 2517.0391 - mse: 18861446.0000 - val_loss: 20654310.0000 - val_mae: 2691.1423 - val_mse: 20654310.0000\n",
            "Epoch 131/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18840922.0000 - mae: 2494.5891 - mse: 18840922.0000 - val_loss: 20616560.0000 - val_mae: 2654.2085 - val_mse: 20616560.0000\n",
            "Epoch 132/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18821342.0000 - mae: 2474.6877 - mse: 18821342.0000 - val_loss: 20596692.0000 - val_mae: 2656.6606 - val_mse: 20596692.0000\n",
            "Epoch 133/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18808276.0000 - mae: 2478.8379 - mse: 18808276.0000 - val_loss: 20586370.0000 - val_mae: 2665.9553 - val_mse: 20586370.0000\n",
            "Epoch 134/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18826980.0000 - mae: 2481.8005 - mse: 18826980.0000 - val_loss: 20563642.0000 - val_mae: 2647.2148 - val_mse: 20563642.0000\n",
            "Epoch 135/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18791182.0000 - mae: 2496.4919 - mse: 18791182.0000 - val_loss: 20535990.0000 - val_mae: 2669.7214 - val_mse: 20535990.0000\n",
            "Epoch 136/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18778166.0000 - mae: 2496.8975 - mse: 18778166.0000 - val_loss: 20521468.0000 - val_mae: 2664.6553 - val_mse: 20521468.0000\n",
            "Epoch 137/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 18767502.0000 - mae: 2472.0613 - mse: 18767502.0000 - val_loss: 20497078.0000 - val_mae: 2653.1147 - val_mse: 20497078.0000\n",
            "Epoch 138/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18757950.0000 - mae: 2472.9817 - mse: 18757950.0000 - val_loss: 20484972.0000 - val_mae: 2655.3289 - val_mse: 20484972.0000\n",
            "Epoch 139/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18743644.0000 - mae: 2486.9255 - mse: 18743644.0000 - val_loss: 20466494.0000 - val_mae: 2656.4690 - val_mse: 20466494.0000\n",
            "Epoch 140/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18739144.0000 - mae: 2503.1245 - mse: 18739144.0000 - val_loss: 20442168.0000 - val_mae: 2664.4968 - val_mse: 20442168.0000\n",
            "Epoch 141/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 18716762.0000 - mae: 2471.9707 - mse: 18716762.0000 - val_loss: 20420788.0000 - val_mae: 2640.3369 - val_mse: 20420788.0000\n",
            "Epoch 142/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18705780.0000 - mae: 2466.0701 - mse: 18705780.0000 - val_loss: 20391396.0000 - val_mae: 2638.5898 - val_mse: 20391396.0000\n",
            "Epoch 143/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 18690452.0000 - mae: 2470.2874 - mse: 18690452.0000 - val_loss: 20387936.0000 - val_mae: 2646.1707 - val_mse: 20387936.0000\n",
            "Epoch 144/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 18693634.0000 - mae: 2491.8853 - mse: 18693634.0000 - val_loss: 20363362.0000 - val_mae: 2654.7827 - val_mse: 20363362.0000\n",
            "Epoch 145/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18673882.0000 - mae: 2485.5166 - mse: 18673882.0000 - val_loss: 20357032.0000 - val_mae: 2649.4690 - val_mse: 20357032.0000\n",
            "Epoch 146/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18655920.0000 - mae: 2470.5176 - mse: 18655920.0000 - val_loss: 20338284.0000 - val_mae: 2622.9780 - val_mse: 20338284.0000\n",
            "Epoch 147/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18655620.0000 - mae: 2477.4639 - mse: 18655620.0000 - val_loss: 20312770.0000 - val_mae: 2631.9644 - val_mse: 20312770.0000\n",
            "Epoch 148/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 18654244.0000 - mae: 2482.8110 - mse: 18654244.0000 - val_loss: 20291470.0000 - val_mae: 2635.0725 - val_mse: 20291470.0000\n",
            "Epoch 149/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18620394.0000 - mae: 2467.9678 - mse: 18620394.0000 - val_loss: 20284492.0000 - val_mae: 2615.3823 - val_mse: 20284492.0000\n",
            "Epoch 150/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18627876.0000 - mae: 2437.4001 - mse: 18627876.0000 - val_loss: 20267454.0000 - val_mae: 2606.8381 - val_mse: 20267454.0000\n",
            "Epoch 151/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18624216.0000 - mae: 2473.8730 - mse: 18624216.0000 - val_loss: 20245064.0000 - val_mae: 2625.4395 - val_mse: 20245064.0000\n",
            "Epoch 152/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18608070.0000 - mae: 2452.1936 - mse: 18608070.0000 - val_loss: 20224718.0000 - val_mae: 2609.4939 - val_mse: 20224718.0000\n",
            "Epoch 153/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18581300.0000 - mae: 2454.1240 - mse: 18581300.0000 - val_loss: 20209882.0000 - val_mae: 2631.3733 - val_mse: 20209882.0000\n",
            "Epoch 154/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18592888.0000 - mae: 2478.7722 - mse: 18592888.0000 - val_loss: 20182562.0000 - val_mae: 2630.9329 - val_mse: 20182562.0000\n",
            "Epoch 155/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18577260.0000 - mae: 2452.5728 - mse: 18577260.0000 - val_loss: 20188890.0000 - val_mae: 2618.4685 - val_mse: 20188890.0000\n",
            "Epoch 156/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18560278.0000 - mae: 2453.0090 - mse: 18560278.0000 - val_loss: 20145324.0000 - val_mae: 2624.7576 - val_mse: 20145324.0000\n",
            "Epoch 157/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18565542.0000 - mae: 2486.1826 - mse: 18565542.0000 - val_loss: 20147412.0000 - val_mae: 2631.5764 - val_mse: 20147412.0000\n",
            "Epoch 158/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 18537496.0000 - mae: 2463.8120 - mse: 18537496.0000 - val_loss: 20116836.0000 - val_mae: 2601.8525 - val_mse: 20116836.0000\n",
            "Epoch 159/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18523706.0000 - mae: 2445.6123 - mse: 18523706.0000 - val_loss: 20111604.0000 - val_mae: 2595.4822 - val_mse: 20111604.0000\n",
            "Epoch 160/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18516888.0000 - mae: 2439.2283 - mse: 18516888.0000 - val_loss: 20105456.0000 - val_mae: 2596.5791 - val_mse: 20105456.0000\n",
            "Epoch 161/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18516452.0000 - mae: 2450.7026 - mse: 18516452.0000 - val_loss: 20087490.0000 - val_mae: 2623.5654 - val_mse: 20087490.0000\n",
            "Epoch 162/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18504416.0000 - mae: 2461.5168 - mse: 18504416.0000 - val_loss: 20067252.0000 - val_mae: 2604.6604 - val_mse: 20067252.0000\n",
            "Epoch 163/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18492114.0000 - mae: 2456.9900 - mse: 18492114.0000 - val_loss: 20037476.0000 - val_mae: 2611.4910 - val_mse: 20037476.0000\n",
            "Epoch 164/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18482792.0000 - mae: 2441.5842 - mse: 18482792.0000 - val_loss: 20030734.0000 - val_mae: 2595.6299 - val_mse: 20030734.0000\n",
            "Epoch 165/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18479556.0000 - mae: 2438.3960 - mse: 18479556.0000 - val_loss: 20021870.0000 - val_mae: 2575.8955 - val_mse: 20021870.0000\n",
            "Epoch 166/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18462722.0000 - mae: 2432.1738 - mse: 18462722.0000 - val_loss: 19997624.0000 - val_mae: 2596.6631 - val_mse: 19997624.0000\n",
            "Epoch 167/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18452850.0000 - mae: 2451.2241 - mse: 18452850.0000 - val_loss: 19996590.0000 - val_mae: 2615.5496 - val_mse: 19996590.0000\n",
            "Epoch 168/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18447992.0000 - mae: 2460.6602 - mse: 18447992.0000 - val_loss: 19980352.0000 - val_mae: 2616.1042 - val_mse: 19980352.0000\n",
            "Epoch 169/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18441184.0000 - mae: 2459.4307 - mse: 18441184.0000 - val_loss: 19968836.0000 - val_mae: 2604.4714 - val_mse: 19968836.0000\n",
            "Epoch 170/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18433328.0000 - mae: 2432.7454 - mse: 18433328.0000 - val_loss: 19925064.0000 - val_mae: 2586.2332 - val_mse: 19925064.0000\n",
            "Epoch 171/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18416430.0000 - mae: 2440.0566 - mse: 18416430.0000 - val_loss: 19939560.0000 - val_mae: 2594.7610 - val_mse: 19939562.0000\n",
            "Epoch 172/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18413790.0000 - mae: 2444.0715 - mse: 18413790.0000 - val_loss: 19904276.0000 - val_mae: 2605.0466 - val_mse: 19904276.0000\n",
            "Epoch 173/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18408762.0000 - mae: 2438.8547 - mse: 18408762.0000 - val_loss: 19905166.0000 - val_mae: 2577.6602 - val_mse: 19905166.0000\n",
            "Epoch 174/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18406154.0000 - mae: 2437.5027 - mse: 18406154.0000 - val_loss: 19878478.0000 - val_mae: 2605.6865 - val_mse: 19878478.0000\n",
            "Epoch 175/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18390060.0000 - mae: 2434.1841 - mse: 18390060.0000 - val_loss: 19868444.0000 - val_mae: 2570.0815 - val_mse: 19868444.0000\n",
            "Epoch 176/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18380674.0000 - mae: 2424.5439 - mse: 18380674.0000 - val_loss: 19863900.0000 - val_mae: 2589.2893 - val_mse: 19863900.0000\n",
            "Epoch 177/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 18384676.0000 - mae: 2454.1072 - mse: 18384676.0000 - val_loss: 19865694.0000 - val_mae: 2620.1309 - val_mse: 19865694.0000\n",
            "Epoch 178/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 18353918.0000 - mae: 2451.0449 - mse: 18353918.0000 - val_loss: 19820816.0000 - val_mae: 2573.6057 - val_mse: 19820816.0000\n",
            "Epoch 179/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18360196.0000 - mae: 2414.1357 - mse: 18360196.0000 - val_loss: 19831632.0000 - val_mae: 2550.7102 - val_mse: 19831632.0000\n",
            "Epoch 180/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18352716.0000 - mae: 2423.1406 - mse: 18352716.0000 - val_loss: 19807094.0000 - val_mae: 2583.9194 - val_mse: 19807094.0000\n",
            "Epoch 181/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18346674.0000 - mae: 2447.6841 - mse: 18346674.0000 - val_loss: 19793824.0000 - val_mae: 2583.4387 - val_mse: 19793824.0000\n",
            "Epoch 182/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18332530.0000 - mae: 2424.3491 - mse: 18332530.0000 - val_loss: 19786020.0000 - val_mae: 2563.4460 - val_mse: 19786020.0000\n",
            "Epoch 183/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18332016.0000 - mae: 2429.2927 - mse: 18332016.0000 - val_loss: 19761778.0000 - val_mae: 2569.8511 - val_mse: 19761778.0000\n",
            "Epoch 184/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 18322448.0000 - mae: 2409.9233 - mse: 18322448.0000 - val_loss: 19750670.0000 - val_mae: 2551.9663 - val_mse: 19750670.0000\n",
            "Epoch 185/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18321236.0000 - mae: 2430.2654 - mse: 18321236.0000 - val_loss: 19754906.0000 - val_mae: 2580.5227 - val_mse: 19754906.0000\n",
            "Epoch 186/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18305230.0000 - mae: 2448.4319 - mse: 18305230.0000 - val_loss: 19727276.0000 - val_mae: 2596.5332 - val_mse: 19727276.0000\n",
            "Epoch 187/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18310610.0000 - mae: 2452.1274 - mse: 18310610.0000 - val_loss: 19731176.0000 - val_mae: 2579.9512 - val_mse: 19731176.0000\n",
            "Epoch 188/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18296696.0000 - mae: 2416.7766 - mse: 18296696.0000 - val_loss: 19725380.0000 - val_mae: 2559.8435 - val_mse: 19725380.0000\n",
            "Epoch 189/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18283712.0000 - mae: 2419.6577 - mse: 18283712.0000 - val_loss: 19706840.0000 - val_mae: 2560.9421 - val_mse: 19706840.0000\n",
            "Epoch 190/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18280816.0000 - mae: 2419.8689 - mse: 18280816.0000 - val_loss: 19700726.0000 - val_mae: 2570.7812 - val_mse: 19700726.0000\n",
            "Epoch 191/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 18280456.0000 - mae: 2424.7202 - mse: 18280456.0000 - val_loss: 19675184.0000 - val_mae: 2555.4421 - val_mse: 19675184.0000\n",
            "Epoch 192/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18265864.0000 - mae: 2429.5681 - mse: 18265864.0000 - val_loss: 19666900.0000 - val_mae: 2567.6836 - val_mse: 19666900.0000\n",
            "Epoch 193/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18261348.0000 - mae: 2431.4512 - mse: 18261348.0000 - val_loss: 19638076.0000 - val_mae: 2572.6814 - val_mse: 19638076.0000\n",
            "Epoch 194/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18253888.0000 - mae: 2431.6697 - mse: 18253888.0000 - val_loss: 19650604.0000 - val_mae: 2562.3225 - val_mse: 19650604.0000\n",
            "Epoch 195/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18245392.0000 - mae: 2423.1848 - mse: 18245392.0000 - val_loss: 19666184.0000 - val_mae: 2550.6255 - val_mse: 19666184.0000\n",
            "Epoch 196/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 18244980.0000 - mae: 2419.9832 - mse: 18244980.0000 - val_loss: 19640462.0000 - val_mae: 2568.7327 - val_mse: 19640462.0000\n",
            "Epoch 197/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18233214.0000 - mae: 2417.8047 - mse: 18233214.0000 - val_loss: 19610958.0000 - val_mae: 2554.0686 - val_mse: 19610958.0000\n",
            "Epoch 198/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 18223194.0000 - mae: 2419.2065 - mse: 18223194.0000 - val_loss: 19585304.0000 - val_mae: 2557.7446 - val_mse: 19585304.0000\n",
            "Epoch 199/200\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 18235628.0000 - mae: 2438.5955 - mse: 18235628.0000 - val_loss: 19579048.0000 - val_mae: 2553.1328 - val_mse: 19579048.0000\n",
            "Epoch 200/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 18219084.0000 - mae: 2396.1597 - mse: 18219084.0000 - val_loss: 19578456.0000 - val_mae: 2517.5081 - val_mse: 19578456.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xe7RXH3N3CWU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "5a225658-f9c3-4384-8817-f290aaa5e611"
      },
      "source": [
        "# RUN THIS CELL TO TEST YOUR MODEL. DO NOT MODIFY CONTENTS.\n",
        "# Test model by checking how well the model generalizes using the test set.\n",
        "loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=2)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} expenses\".format(mae))\n",
        "\n",
        "if mae < 3500:\n",
        "  print(\"You passed the challenge. Great job!\")\n",
        "else:\n",
        "  print(\"The Mean Abs Error must be less than 3500. Keep trying.\")\n",
        "\n",
        "# Plot predictions.\n",
        "test_predictions = model.predict(test_dataset).flatten()\n",
        "\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True values (expenses)')\n",
        "plt.ylabel('Predictions (expenses)')\n",
        "lims = [0, 50000]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims,lims)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 - 0s - loss: 31447602.0000 - mae: 3105.6809 - mse: 31447602.0000\n",
            "Testing set Mean Abs Error: 3105.68 expenses\n",
            "You passed the challenge. Great job!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}